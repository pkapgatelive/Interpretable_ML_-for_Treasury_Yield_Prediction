# Interpretable Machine-Learning Models for Yield-Curve Forecasting and Monetary-Policy Scenario Analysis

[![Python](https://img.shields.io/badge/python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

## ğŸ“– Project Overview

This project develops interpretable machine learning models for forecasting government bond yield curves and conducting monetary policy scenario analysis. The research focuses on creating transparent, explainable models that can assist central banks and financial institutions in understanding interest rate dynamics and policy impacts.

### ğŸ¯ Objectives

- **Yield Curve Forecasting**: Develop accurate ML models to predict future yield curve shapes
- **Policy Impact Analysis**: Simulate how monetary policy changes affect interest rate structures
- **Model Interpretability**: Ensure all models provide clear, actionable insights using SHAP and other explainability techniques
- **Academic Rigor**: Maintain reproducible research standards suitable for publication

## ğŸ—‚ï¸ Project Organization

```
â”œâ”€â”€ README.md                     <- The top-level README for developers using this project
â”œâ”€â”€ requirements.txt              <- Python dependencies for reproducing the environment
â”œâ”€â”€ environment.yml               <- Conda environment specification
â”œâ”€â”€ pyproject.toml               <- Modern Python project configuration
â”œâ”€â”€ .gitignore                   <- Git ignore patterns
â”œâ”€â”€ .pre-commit-config.yaml      <- Pre-commit hooks configuration
â”œâ”€â”€ dvc.yaml                     <- DVC pipeline configuration
â”‚
â”œâ”€â”€ config/                      <- Configuration files
â”‚   â”œâ”€â”€ config.yaml             <- Main project configuration
â”‚   â””â”€â”€ model_config.yaml       <- Model-specific parameters
â”‚
â”œâ”€â”€ data/                        <- Data directory (tracked with DVC)
â”‚   â”œâ”€â”€ raw/                    <- Original, immutable data
â”‚   â”œâ”€â”€ processed/              <- Cleaned and transformed data
â”‚   â”œâ”€â”€ features/               <- Engineered features for modeling
â”‚   â””â”€â”€ external/               <- External reference data
â”‚
â”œâ”€â”€ src/                         <- Source code for use in this project
â”‚   â”œâ”€â”€ data/                   <- Data loading and processing modules
â”‚   â”œâ”€â”€ models/                 <- Model training and evaluation code
â”‚   â”œâ”€â”€ visualization/          <- Plotting and dashboard utilities
â”‚   â”œâ”€â”€ explainability/         <- Model interpretation tools
â”‚   â””â”€â”€ utils/                  <- Utility functions and constants
â”‚
â”œâ”€â”€ notebooks/                   <- Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_baseline_models.ipynb
â”‚   â”œâ”€â”€ 04_ml_models.ipynb
â”‚   â”œâ”€â”€ 05_explainability_analysis.ipynb
â”‚   â””â”€â”€ 06_policy_scenario_simulation.ipynb
â”‚
â”œâ”€â”€ models/                      <- Trained models and artifacts
â”‚   â”œâ”€â”€ trained/                <- Final trained models
â”‚   â”œâ”€â”€ checkpoints/            <- Model checkpoints during training
â”‚   â””â”€â”€ artifacts/              <- Model metadata and performance metrics
â”‚
â”œâ”€â”€ reports/                     <- Generated reports and visualizations
â”‚   â”œâ”€â”€ figures/                <- Publication-ready figures
â”‚   â”œâ”€â”€ tables/                 <- Results tables and summaries
â”‚   â””â”€â”€ presentations/          <- Presentation materials
â”‚
â”œâ”€â”€ scripts/                     <- Standalone scripts for automation
â”‚   â”œâ”€â”€ train_model.py          <- Model training pipeline
â”‚   â”œâ”€â”€ evaluate_model.py       <- Model evaluation script
â”‚   â”œâ”€â”€ generate_forecasts.py   <- Forecast generation
â”‚   â””â”€â”€ run_pipeline.py         <- Full pipeline execution
â”‚
â””â”€â”€ tests/                       <- Unit tests
    â”œâ”€â”€ test_data/              <- Data processing tests
    â”œâ”€â”€ test_models/            <- Model testing
    â””â”€â”€ test_utils/             <- Utility function tests
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- Git
- DVC (Data Version Control)
- Conda or pip for package management

### Installation

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd yield-curve-forecasting
   ```

2. **Set up the environment**:
   
   Using conda:
   ```bash
   conda env create -f environment.yml
   conda activate yield-forecasting
   ```
   
   Or using pip:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Install pre-commit hooks**:
   ```bash
   pre-commit install
   ```

4. **Initialize DVC** (if not already done):
   ```bash
   dvc init
   ```

### First Steps

1. **Explore the data**: Start with `notebooks/01_data_exploration.ipynb`
2. **Configure parameters**: Edit `config/config.yaml` for your specific use case
3. **Run the pipeline**: Execute `python scripts/run_pipeline.py`

## ğŸ“Š Data Sources

*[To be completed with specific yield curve data sources]*

- Federal Reserve Economic Data (FRED)
- Central bank databases
- Bloomberg/Refinitiv data feeds
- Academic datasets

## ğŸ”¬ Methodology

### Models Implemented
- **Baseline Models**: Linear regression, ARIMA, Nelson-Siegel
- **Machine Learning**: Random Forest, Gradient Boosting, Neural Networks
- **Ensemble Methods**: Stacking, voting classifiers
- **Deep Learning**: LSTM, Transformer architectures

### Interpretability Techniques
- SHAP (SHapley Additive exPlanations)
- LIME (Local Interpretable Model-agnostic Explanations)
- Feature importance analysis
- Partial dependence plots

## ğŸ“ˆ Results

*[To be completed with model performance metrics]*

## ğŸ“ Publication Status

*[To be updated with publication information]*

- Conference submissions: [TBD]
- Journal submissions: [TBD]
- Working papers: [TBD]

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“§ Contact

[Your Name] - [your.email@institution.edu]

Project Link: [https://github.com/username/yield-curve-forecasting](https://github.com/username/yield-curve-forecasting)

## ğŸ™ Acknowledgments

- [Research institution/supervisor acknowledgments]
- [Data provider acknowledgments]
- [Funding source acknowledgments] 